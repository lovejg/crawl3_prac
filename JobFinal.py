import requests
from bs4 import BeautifulSoup
from bs4 import NavigableString
import mysql.connector
from mysql.connector import Error
import time

db_config = {
    'host': 'localhost',
    'user': 'root',
    'password': '1234',
    'database': 'recruit',
    'port': 3307,
}

def create_connection(config):
    connection = None
    try:
        connection = mysql.connector.connect(**config)
        print("ğŸ‰ MySQL DBì— ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Error as e:
        print(f"DB ì—°ê²° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    return connection

def crawl_detail_page(detail_url):
    """ìƒì„¸í˜ì´ì§€ì—ì„œ ì¶”ê°€ ì •ë³´ë¥¼ í¬ë¡¤ë§ (í•„ìš”ì‹œ í™œìš© ê°€ëŠ¥)"""
    try:
        time.sleep(1)
        soup = requests.get(detail_url, headers={'User-Agent': 'Mozilla/5.0'})
        html = BeautifulSoup(soup.text, 'html.parser').select_one("section#container")
        
        if not html:
            return {}
        
        main_info = html.select_one('section.secReadSummary')
        if not main_info:
            return {}
        
        detail_data = {}
        
        dl_tag1 = main_info.select('dl.tbList')
        if dl_tag1:
            dt_tags = dl_tag1[0].find_all('dt')
            skills = ""
            for dt in dt_tags:
                if dt.text.strip() == "ìŠ¤í‚¬":
                    dd = dt.find_next_sibling('dd')
                    if dd:
                        skills = dd.get_text(strip=True)
                    break
            detail_data['skills'] = skills
        
        return detail_data
        
    except Exception as e:
        print(f"ìƒì„¸í˜ì´ì§€ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {}

def insert_job_data(cursor, data):
    query = """
        INSERT INTO recruitment
        (title, company_name, company_location, is_regular, require_career, 
         require_education, advantage, detail_url, expire_date) 
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
    """
    try:
        cursor.execute(query, data)
        print(f"âœ… ë°ì´í„° ì‚½ì… ì™„ë£Œ: {data[0]}")
    except Error as e:
        print(f"ë°ì´í„° ì‚½ì… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

keyword = input("í‚¤ì›Œë“œ ì…ë ¥: ")
pageNum = input("ëª‡ í˜ì´ì§€ê¹Œì§€ ì¶œë ¥í• ì§€(í¬ë¡¤ë§í• ì§€): ")
print(f"í‚¤ì›Œë“œ '{keyword}'ë¡œ ì±„ìš©ì •ë³´ í¬ë¡¤ë§ì„ ì‹œì‘")

conn = create_connection(db_config)
if conn is None:
    exit()

cursor = conn.cursor()

total_jobs = 0

for n in range(1, int(pageNum)+1):
    try:
        print(f"\nğŸ“„ {n}í˜ì´ì§€ í¬ë¡¤ë§ ì¤‘...")
        soup = requests.get('https://www.jobkorea.co.kr/Search/?stext={}&Page_No={}'.format(keyword, str(n)),
                           headers={'User-Agent': 'Mozilla/5.0'})
        html = BeautifulSoup(soup.text, 'html.parser').select_one(".Tabs_content__1cw1bssl")
        
        if not html:
            print(f"{n}í˜ì´ì§€: ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue
        
        jobs = html.select('.h7nnv10')
        
        for job in jobs:
            try:
                # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
                company = job.select_one('span.Typography_variant_size16__344nw26').text.strip()
                title = job.select_one('a.sn28bt0').text.strip()
                url = job.find('a')['href']
                
                # ì „ì²´ URLë¡œ ë³€í™˜
                if not url.startswith('http'):
                    url = 'https://www.jobkorea.co.kr' + url
                
                # ê²½ë ¥, í•™ë ¥ ë“± ì •ë³´ ì¶”ì¶œ
                items = job.select('span.Typography_color_gray700__344nw2m')
                start_index = -1
                for i, item in enumerate(items):
                    if item.text.strip().startswith(('ê²½ë ¥', 'ì‹ ì…')):
                        start_index = i
                        break
                
                if start_index != -1:
                    info_list = items[start_index:]
                else:
                    continue
                
                if len(info_list) < 5:
                    continue
                
                career = info_list[0].text.strip()
                edu_career = info_list[1].text.strip()
                regular = info_list[2].text.strip()
                location = info_list[3].text.strip()
                deadline = info_list[4].text.strip()
                
                benefit_tags = job.select('span.Typography_variant_size13__344nw29')
                benefit = ', '.join([tag.text.strip() for tag in benefit_tags]) if benefit_tags else ''
                
                job_data = (
                    title, company, location, regular, career, 
                    edu_career, benefit, url, deadline
                )
                
                insert_job_data(cursor, job_data)
                total_jobs += 1
                
            except Exception as e:
                print(f"  âŒ ê°œë³„ ê³µê³  ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
                
    except Exception as e:
        print(f"{n}í˜ì´ì§€ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        continue

# ìµœì¢… ì €ì¥
conn.commit()
cursor.close()
conn.close()

print(f"\nğŸ‰ ëª¨ë“  í¬ë¡¤ë§ ë° DB ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
print(f"ğŸ“Š ì´ {total_jobs}ê°œì˜ ì±„ìš©ê³µê³ ê°€ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")